{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifahsaan/Deep-Learning/blob/main/Full_Image_Classification_Workflow_Recreated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84c8efc8",
      "metadata": {
        "id": "84c8efc8"
      },
      "source": [
        "# üß† Complete Beginner's Notebook: Image Preprocessing, Classification & Prediction\n",
        "This notebook walks you through the entire image classification pipeline using TensorFlow and Keras.\n",
        "From loading data, preprocessing, training a CNN model, to evaluating and predicting new images."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cea428",
      "metadata": {
        "id": "47cea428"
      },
      "source": [
        "## üì¶ Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b49b1c3",
      "metadata": {
        "id": "6b49b1c3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "044c0aa3",
      "metadata": {
        "id": "044c0aa3"
      },
      "source": [
        "## üóÇÔ∏è Step 2: Load the Flower Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce57d206",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce57d206",
        "outputId": "66f22160-a121-4d5c-b0fd-c746063e7fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "\u001b[1m228813984/228813984\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Dataset loaded from: /root/.keras/datasets/flower_photos\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, fname='flower_photos', untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "print(\"Dataset loaded from:\", data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35501c51",
      "metadata": {
        "id": "35501c51"
      },
      "source": [
        "## üñºÔ∏è Step 3: View a Sample Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a03dae1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a03dae1",
        "outputId": "939aca01-e383-4d1c-ab7c-11bc59fb6e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flower_photos: 6 images\n"
          ]
        }
      ],
      "source": [
        "# # Download the dataset again\n",
        "# dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "# data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
        "#                                    fname='flower_photos',\n",
        "#                                    untar=True)\n",
        "# data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "# Check the contents\n",
        "for folder in data_dir.iterdir():\n",
        "    print(f\"{folder.name}: {len(list(folder.glob('*')))} images\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Try to load a sample image from the first available class\n",
        "for class_folder in data_dir.iterdir():\n",
        "    # Filter for common image file extensions\n",
        "    image_files = [f for f in class_folder.glob(\"*\") if f.suffix in ['.jpg', '.jpeg', '.png', '.bmp']]\n",
        "    if image_files:\n",
        "        sample_img_path = image_files[0]\n",
        "        try:\n",
        "            img = Image.open(sample_img_path)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Sample Image - {class_folder.name}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "            break # Stop after finding and displaying one image\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Could not identify image file: {sample_img_path}\")\n",
        "            continue # Skip to the next file if identification fails\n",
        "\n",
        "else:\n",
        "    print(\"No image files found in any category.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElshLVamerMD",
        "outputId": "e849a019-6467-4afc-86ca-857c82fe3f22"
      },
      "id": "ElshLVamerMD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No image files found in any category.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f6f71c6",
      "metadata": {
        "id": "3f6f71c6"
      },
      "source": [
        "## üßπ Step 4: Resize and Normalize the Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f44f6f1",
      "metadata": {
        "id": "5f44f6f1"
      },
      "outputs": [],
      "source": [
        "img_resized = img.resize((128, 128))\n",
        "img_array = np.array(img_resized) / 255.0\n",
        "print(\"Resized shape:\", img_array.shape)\n",
        "plt.imshow(img_array)\n",
        "plt.title(\"Resized and Normalized Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66c897ad",
      "metadata": {
        "id": "66c897ad"
      },
      "source": [
        "## üìÇ Step 5: Load Dataset for Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e78621bb",
      "metadata": {
        "id": "e78621bb"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size)\n",
        "class_names = train_ds.class_names\n",
        "print(\"Class names:\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9eecd2e",
      "metadata": {
        "id": "c9eecd2e"
      },
      "source": [
        "## ‚öôÔ∏è Step 6: Optimize Dataset Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b1d524",
      "metadata": {
        "id": "a3b1d524"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc55195b",
      "metadata": {
        "id": "bc55195b"
      },
      "source": [
        "## üß† Step 7: Define the CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a69fc11",
      "metadata": {
        "id": "0a69fc11"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(len(class_names))\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e662287",
      "metadata": {
        "id": "8e662287"
      },
      "source": [
        "## üöÄ Step 8: Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cbc8738",
      "metadata": {
        "id": "3cbc8738"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384dd206",
      "metadata": {
        "id": "384dd206"
      },
      "source": [
        "## üìä Step 9: Evaluation Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80454c05",
      "metadata": {
        "id": "80454c05"
      },
      "outputs": [],
      "source": [
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "y_pred_probs = model.predict(val_ds)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77f4d4e4",
      "metadata": {
        "id": "77f4d4e4"
      },
      "source": [
        "## üîÆ Step 10: Predict a New Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa41ef1",
      "metadata": {
        "id": "6aa41ef1"
      },
      "outputs": [],
      "source": [
        "def predict_image(image_path):\n",
        "    img = tf.keras.utils.load_img(image_path, target_size=(img_height, img_width))\n",
        "    img_array = tf.keras.utils.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    predictions = model.predict(img_array)\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "    predicted_class = class_names[np.argmax(score)]\n",
        "    confidence = 100 * np.max(score)\n",
        "    print(f\"Predicted: {predicted_class} with {confidence:.2f}% confidence\")\n",
        "\n",
        "# Example:\n",
        "# predict_image('/path/to/image.jpg')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}