{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asifahsaan/Deep-Learning/blob/main/Image_Preprocessing_and_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f035461c",
      "metadata": {
        "id": "f035461c"
      },
      "source": [
        "# üß† Image Preprocessing & Augmentation Notebook\n",
        "This notebook demonstrates comprehensive image preprocessing techniques used in image classification workflows:\n",
        "- Image loading and normalization\n",
        "- Resizing and grayscale conversion\n",
        "- Brightness, contrast, and flipping\n",
        "- Augmentation pipeline with `tf.image` and `Keras` layers\n",
        "- Visualization of augmented images"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ae7387",
      "metadata": {
        "id": "01ae7387"
      },
      "source": [
        "## üì¶ Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86cc0b4",
      "metadata": {
        "id": "a86cc0b4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import pathlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36480f79",
      "metadata": {
        "id": "36480f79"
      },
      "source": [
        "## üóÇÔ∏è Step 2: Load the Flower Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "045fa49c",
      "metadata": {
        "id": "045fa49c"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir) / 'flower_photos'\n",
        "class_names = sorted([item.name for item in data_dir.glob('*') if item.is_dir()])\n",
        "print(\"Classes:\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c2be852",
      "metadata": {
        "id": "3c2be852"
      },
      "source": [
        "## üñºÔ∏è Step 3: Load a Batch of Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98bc53bd",
      "metadata": {
        "id": "98bc53bd"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=42,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f82e5f2",
      "metadata": {
        "id": "9f82e5f2"
      },
      "source": [
        "## üëÅÔ∏è Step 4: View Original Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ad1121",
      "metadata": {
        "id": "a8ad1121"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbc727e",
      "metadata": {
        "id": "9fbc727e"
      },
      "source": [
        "## üî¢ Step 5: Normalize Image Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d30926a",
      "metadata": {
        "id": "0d30926a"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
        "for image_batch, _ in normalized_ds.take(1):\n",
        "    print(\"Min pixel:\", tf.reduce_min(image_batch).numpy())\n",
        "    print(\"Max pixel:\", tf.reduce_max(image_batch).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b299f697",
      "metadata": {
        "id": "b299f697"
      },
      "source": [
        "## üåë Step 6: Convert to Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19998408",
      "metadata": {
        "id": "19998408"
      },
      "outputs": [],
      "source": [
        "def to_grayscale(images):\n",
        "    return tf.image.rgb_to_grayscale(images)\n",
        "\n",
        "for images, _ in train_ds.take(1):\n",
        "    gray_images = to_grayscale(images)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(8):\n",
        "        ax = plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(tf.squeeze(gray_images[i]), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(\"Grayscale Images\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b686f7f0",
      "metadata": {
        "id": "b686f7f0"
      },
      "source": [
        "## üé® Step 7: Image Augmentation using `tf.image`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83fc7360",
      "metadata": {
        "id": "83fc7360"
      },
      "outputs": [],
      "source": [
        "def augment_image_tf(img):\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
        "    return img\n",
        "\n",
        "for images, _ in train_ds.take(1):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(8):\n",
        "        augmented = augment_image_tf(images[i])\n",
        "        ax = plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(tf.cast(augmented, tf.uint8))\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(\"Augmented Images (Brightness, Contrast, Flip)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62c633d8",
      "metadata": {
        "id": "62c633d8"
      },
      "source": [
        "## üß± Step 8: Image Augmentation using `tf.keras.layers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b48c84b",
      "metadata": {
        "id": "7b48c84b"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.1),\n",
        "    tf.keras.layers.RandomZoom(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "for images, _ in train_ds.take(1):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(8):\n",
        "        augmented = data_augmentation(images[i:i+1])\n",
        "        ax = plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(augmented[0].numpy().astype('uint8'))\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(\"Augmented Images via Keras Layers\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}